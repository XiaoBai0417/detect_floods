{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOEzZn1w01Uk"
      },
      "outputs": [],
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJOb57DD-6nC"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TNKykwpaHHYH",
        "outputId": "d9923d61-9834-465c-e59b-21bf71a3595b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting geemap==0.15.1\n",
            "  Downloading geemap-0.15.1-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 2.1 MB/s \n",
            "\u001b[?25hCollecting ee-extra>=0.0.10\n",
            "  Downloading ee_extra-0.0.14.tar.gz (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 57.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from geemap==0.15.1) (1.3.5)\n",
            "Collecting xyzservices\n",
            "  Downloading xyzservices-2022.9.0-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting colour\n",
            "  Downloading colour-0.1.5-py2.py3-none-any.whl (23 kB)\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (from geemap==0.15.1) (4.4.0)\n",
            "Collecting pyshp>=2.1.3\n",
            "  Downloading pyshp-2.3.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.8 MB/s \n",
            "\u001b[?25hCollecting ipyleaflet>=0.17.0\n",
            "  Downloading ipyleaflet-0.17.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 40.1 MB/s \n",
            "\u001b[?25hCollecting ipytree\n",
            "  Downloading ipytree-0.2.2-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 46.0 MB/s \n",
            "\u001b[?25hCollecting jupyterlab>=3\n",
            "  Downloading jupyterlab-3.4.7-py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 39.2 MB/s \n",
            "\u001b[?25hCollecting ipyevents\n",
            "  Downloading ipyevents-2.0.1-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 69.3 MB/s \n",
            "\u001b[?25hCollecting python-box\n",
            "  Downloading python_box-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 32.2 MB/s \n",
            "\u001b[?25hCollecting geeadd>=0.5.1\n",
            "  Downloading geeadd-0.5.6-py3-none-any.whl (30 kB)\n",
            "Collecting ipyfilechooser>=0.6.0\n",
            "  Downloading ipyfilechooser-0.6.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: earthengine-api>=0.1.304 in /usr/local/lib/python3.7/dist-packages (from geemap==0.15.1) (0.1.323)\n",
            "Requirement already satisfied: folium>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from geemap==0.15.1) (0.12.1.post1)\n",
            "Collecting geojson\n",
            "  Downloading geojson-2.5.0-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from geemap==0.15.1) (3.2.2)\n",
            "Collecting geocoder\n",
            "  Downloading geocoder-1.38.1-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 8.0 MB/s \n",
            "\u001b[?25hCollecting sankee>=0.1.0\n",
            "  Downloading sankee-0.2.0.tar.gz (29 kB)\n",
            "Collecting whiteboxgui>=0.6.0\n",
            "  Downloading whiteboxgui-0.7.0-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 9.4 MB/s \n",
            "\u001b[?25hCollecting pycrs\n",
            "  Downloading PyCRS-1.0.2.tar.gz (36 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from geemap==0.15.1) (7.1.2)\n",
            "Collecting bqplot\n",
            "  Downloading bqplot-0.12.36-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 45.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from geemap==0.15.1) (1.21.6)\n",
            "Collecting scooby\n",
            "  Downloading scooby-0.6.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: httplib2shim in /usr/local/lib/python3.7/dist-packages (from earthengine-api>=0.1.304->geemap==0.15.1) (0.0.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from earthengine-api>=0.1.304->geemap==0.15.1) (0.16.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from earthengine-api>=0.1.304->geemap==0.15.1) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from earthengine-api>=0.1.304->geemap==0.15.1) (0.0.4)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.7/dist-packages (from earthengine-api>=0.1.304->geemap==0.15.1) (1.18.1)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from earthengine-api>=0.1.304->geemap==0.15.1) (1.35.0)\n",
            "Requirement already satisfied: google-api-python-client<2,>=1.12.1 in /usr/local/lib/python3.7/dist-packages (from earthengine-api>=0.1.304->geemap==0.15.1) (1.12.11)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from earthengine-api>=0.1.304->geemap==0.15.1) (1.15.0)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from folium>=0.11.0->geemap==0.15.1) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from folium>=0.11.0->geemap==0.15.1) (2.23.0)\n",
            "Requirement already satisfied: branca>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from folium>=0.11.0->geemap==0.15.1) (0.5.0)\n",
            "Collecting logzero>=1.5.0\n",
            "  Downloading logzero-1.7.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting beautifulsoup4>=4.9.0\n",
            "  Downloading beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 56.3 MB/s \n",
            "\u001b[?25hCollecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.12.1->earthengine-api>=0.1.304->geemap==0.15.1) (1.31.6)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.12.1->earthengine-api>=0.1.304->geemap==0.15.1) (3.0.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client<2,>=1.12.1->earthengine-api>=0.1.304->geemap==0.15.1) (57.4.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client<2,>=1.12.1->earthengine-api>=0.1.304->geemap==0.15.1) (2022.2.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client<2,>=1.12.1->earthengine-api>=0.1.304->geemap==0.15.1) (1.56.4)\n",
            "Requirement already satisfied: protobuf<4.0.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client<2,>=1.12.1->earthengine-api>=0.1.304->geemap==0.15.1) (3.17.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client<2,>=1.12.1->earthengine-api>=0.1.304->geemap==0.15.1) (21.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->earthengine-api>=0.1.304->geemap==0.15.1) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->earthengine-api>=0.1.304->geemap==0.15.1) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->earthengine-api>=0.1.304->geemap==0.15.1) (0.2.8)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from ipyfilechooser>=0.6.0->geemap==0.15.1) (7.7.1)\n",
            "Collecting traittypes<3,>=0.2.1\n",
            "  Downloading traittypes-0.2.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->ipyfilechooser>=0.6.0->geemap==0.15.1) (3.6.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->ipyfilechooser>=0.6.0->geemap==0.15.1) (5.3.4)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->ipyfilechooser>=0.6.0->geemap==0.15.1) (0.2.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->ipyfilechooser>=0.6.0->geemap==0.15.1) (7.9.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->ipyfilechooser>=0.6.0->geemap==0.15.1) (3.0.3)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->ipyfilechooser>=0.6.0->geemap==0.15.1) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->ipyfilechooser>=0.6.0->geemap==0.15.1) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->ipyfilechooser>=0.6.0->geemap==0.15.1) (5.1.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap==0.15.1) (2.6.1)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 41.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap==0.15.1) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap==0.15.1) (0.2.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap==0.15.1) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap==0.15.1) (2.0.10)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap==0.15.1) (4.4.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap==0.15.1) (0.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.9->folium>=0.11.0->geemap==0.15.1) (2.0.1)\n",
            "Collecting jupyterlab-server~=2.10\n",
            "  Downloading jupyterlab_server-2.15.2-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: notebook<7 in /usr/local/lib/python3.7/dist-packages (from jupyterlab>=3->geemap==0.15.1) (5.3.1)\n",
            "Collecting nbclassic\n",
            "  Downloading nbclassic-0.4.3-py3-none-any.whl (9.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.7 MB 45.9 MB/s \n",
            "\u001b[?25hCollecting tornado>=4.2\n",
            "  Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n",
            "\u001b[K     |████████████████████████████████| 423 kB 57.6 MB/s \n",
            "\u001b[?25hCollecting jupyter-server~=1.16\n",
            "  Downloading jupyter_server-1.19.1-py3-none-any.whl (346 kB)\n",
            "\u001b[K     |████████████████████████████████| 346 kB 59.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tomli in /usr/local/lib/python3.7/dist-packages (from jupyterlab>=3->geemap==0.15.1) (2.0.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from jupyterlab>=3->geemap==0.15.1) (4.11.1)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab>=3->geemap==0.15.1) (0.13.3)\n",
            "Requirement already satisfied: nbformat>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab>=3->geemap==0.15.1) (5.4.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab>=3->geemap==0.15.1) (23.2.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab>=3->geemap==0.15.1) (1.8.0)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.4.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting argon2-cffi\n",
            "  Downloading argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
            "Collecting anyio<4,>=3.1.0\n",
            "  Downloading anyio-3.6.1-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 8.8 MB/s \n",
            "\u001b[?25hCollecting nbconvert>=6.4.4\n",
            "  Downloading nbconvert-7.0.0-py3-none-any.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 61.8 MB/s \n",
            "\u001b[?25hCollecting prometheus-client\n",
            "  Downloading prometheus_client-0.14.1-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 7.1 MB/s \n",
            "\u001b[?25hCollecting sniffio>=1.1\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.1.0->jupyter-server~=1.16->jupyterlab>=3->geemap==0.15.1) (4.1.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.1.0->jupyter-server~=1.16->jupyterlab>=3->geemap==0.15.1) (2.10)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->ipyfilechooser>=0.6.0->geemap==0.15.1) (2.8.2)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.10->jupyterlab>=3->geemap==0.15.1) (4.12.0)\n",
            "Collecting jinja2>=2.9\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 57.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.10->jupyterlab>=3->geemap==0.15.1) (2.10.3)\n",
            "Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.10->jupyterlab>=3->geemap==0.15.1) (4.3.3)\n",
            "Collecting json5\n",
            "  Downloading json5-0.9.10-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->jupyterlab-server~=2.10->jupyterlab>=3->geemap==0.15.1) (3.8.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.10->jupyterlab>=3->geemap==0.15.1) (0.18.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.10->jupyterlab>=3->geemap==0.15.1) (22.1.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.10->jupyterlab>=3->geemap==0.15.1) (5.9.0)\n",
            "Collecting tinycss2\n",
            "  Downloading tinycss2-1.1.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab>=3->geemap==0.15.1) (5.0.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab>=3->geemap==0.15.1) (4.9.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab>=3->geemap==0.15.1) (1.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab>=3->geemap==0.15.1) (0.7.1)\n",
            "Collecting nbclient>=0.5.0\n",
            "  Downloading nbclient-0.6.8-py3-none-any.whl (71 kB)\n",
            "\u001b[K     |████████████████████████████████| 71 kB 203 kB/s \n",
            "\u001b[?25hCollecting jupyterlab-pygments\n",
            "  Downloading jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n",
            "Collecting mistune<3,>=2.0.3\n",
            "  Downloading mistune-2.0.4-py2.py3-none-any.whl (24 kB)\n",
            "Collecting traitlets>=4.3.1\n",
            "  Downloading traitlets-5.4.0-py3-none-any.whl (107 kB)\n",
            "\u001b[K     |████████████████████████████████| 107 kB 54.2 MB/s \n",
            "\u001b[?25hCollecting nest-asyncio\n",
            "  Downloading nest_asyncio-1.5.5-py3-none-any.whl (5.2 kB)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=5.2.0->jupyter-server~=1.16->jupyterlab>=3->geemap==0.15.1) (2.16.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client<2,>=1.12.1->earthengine-api>=0.1.304->geemap==0.15.1) (3.0.9)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap==0.15.1) (0.2.5)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->earthengine-api>=0.1.304->geemap==0.15.1) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->folium>=0.11.0->geemap==0.15.1) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->folium>=0.11.0->geemap==0.15.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->folium>=0.11.0->geemap==0.15.1) (1.24.3)\n",
            "Requirement already satisfied: plotly>=5.2.2 in /usr/local/lib/python3.7/dist-packages (from sankee>=0.1.0->geemap==0.15.1) (5.5.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly>=5.2.2->sankee>=0.1.0->geemap==0.15.1) (8.0.1)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.3->jupyter-server~=1.16->jupyterlab>=3->geemap==0.15.1) (0.7.0)\n",
            "Collecting whitebox\n",
            "  Downloading whitebox-2.1.4-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting argon2-cffi-bindings\n",
            "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server~=1.16->jupyterlab>=3->geemap==0.15.1) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server~=1.16->jupyterlab>=3->geemap==0.15.1) (2.21)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab>=3->geemap==0.15.1) (0.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown->geemap==0.15.1) (3.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown->geemap==0.15.1) (4.64.1)\n",
            "Collecting ratelim\n",
            "  Downloading ratelim-0.1.6-py2.py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from geocoder->geemap==0.15.1) (7.1.2)\n",
            "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->earthengine-api>=0.1.304->geemap==0.15.1) (0.4.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->earthengine-api>=0.1.304->geemap==0.15.1) (1.0.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->geemap==0.15.1) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->geemap==0.15.1) (1.4.4)\n",
            "Collecting notebook-shim>=0.1.0\n",
            "  Downloading notebook_shim-0.1.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->folium>=0.11.0->geemap==0.15.1) (1.7.1)\n",
            "Building wheels for collected packages: ee-extra, sankee, pycrs\n",
            "  Building wheel for ee-extra (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ee-extra: filename=ee_extra-0.0.14-py3-none-any.whl size=209114 sha256=69f8c0da6b22e3b2abde089d92826a166f5b3764ab5d27e97b93ef4c16e8cd44\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/1f/56/c638a525bcb6972c82e422747430d756edea7d57b539229bb3\n",
            "  Building wheel for sankee (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sankee: filename=sankee-0.2.0-py3-none-any.whl size=28745 sha256=b63a22736f8fa2403e716974331c2841365e3d4368b5786f3c76c72bab2349f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/36/b4/ac/84c3f06e5c44d3fe5029713232438862881e6e1f26657d5fd8\n",
            "  Building wheel for pycrs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycrs: filename=PyCRS-1.0.2-py3-none-any.whl size=32704 sha256=d0f3598dfab94a0a57a91c52203c4127be23cda8744304bc1ac195ab4a4b977d\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/ce/32/1ec0aba6b9770681a423e82f0274c57d09ad2c20c2864901f9\n",
            "Successfully built ee-extra sankee pycrs\n",
            "Installing collected packages: traitlets, tornado, soupsieve, nest-asyncio, jedi, tinycss2, nbclient, mistune, jupyterlab-pygments, jinja2, beautifulsoup4, sniffio, nbconvert, argon2-cffi-bindings, websocket-client, prometheus-client, argon2-cffi, anyio, jupyter-server, notebook-shim, json5, xyzservices, whitebox, traittypes, ratelim, nbclassic, logzero, jupyterlab-server, ipytree, ipyfilechooser, whiteboxgui, scooby, sankee, python-box, pyshp, pycrs, jupyterlab, ipyleaflet, ipyevents, geojson, geocoder, geeadd, ffmpeg-python, ee-extra, colour, bqplot, geemap\n",
            "  Attempting uninstall: traitlets\n",
            "    Found existing installation: traitlets 5.1.1\n",
            "    Uninstalling traitlets-5.1.1:\n",
            "      Successfully uninstalled traitlets-5.1.1\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 5.1.1\n",
            "    Uninstalling tornado-5.1.1:\n",
            "      Successfully uninstalled tornado-5.1.1\n",
            "  Attempting uninstall: mistune\n",
            "    Found existing installation: mistune 0.8.4\n",
            "    Uninstalling mistune-0.8.4:\n",
            "      Successfully uninstalled mistune-0.8.4\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 2.11.3\n",
            "    Uninstalling Jinja2-2.11.3:\n",
            "      Successfully uninstalled Jinja2-2.11.3\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Attempting uninstall: nbconvert\n",
            "    Found existing installation: nbconvert 5.6.1\n",
            "    Uninstalling nbconvert-5.6.1:\n",
            "      Successfully uninstalled nbconvert-5.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0, but you have tornado 6.2 which is incompatible.\n",
            "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.1.2 which is incompatible.\u001b[0m\n",
            "Successfully installed anyio-3.6.1 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 beautifulsoup4-4.11.1 bqplot-0.12.36 colour-0.1.5 ee-extra-0.0.14 ffmpeg-python-0.2.0 geeadd-0.5.6 geemap-0.15.1 geocoder-1.38.1 geojson-2.5.0 ipyevents-2.0.1 ipyfilechooser-0.6.0 ipyleaflet-0.17.1 ipytree-0.2.2 jedi-0.18.1 jinja2-3.1.2 json5-0.9.10 jupyter-server-1.19.1 jupyterlab-3.4.7 jupyterlab-pygments-0.2.2 jupyterlab-server-2.15.2 logzero-1.7.0 mistune-2.0.4 nbclassic-0.4.3 nbclient-0.6.8 nbconvert-7.0.0 nest-asyncio-1.5.5 notebook-shim-0.1.0 prometheus-client-0.14.1 pycrs-1.0.2 pyshp-2.3.1 python-box-6.0.2 ratelim-0.1.6 sankee-0.2.0 scooby-0.6.0 sniffio-1.3.0 soupsieve-2.3.2.post1 tinycss2-1.1.1 tornado-6.2 traitlets-5.4.0 traittypes-0.2.1 websocket-client-1.4.1 whitebox-2.1.4 whiteboxgui-0.7.0 xyzservices-2022.9.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tornado"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pip install geemap==0.15.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kT9PoQjN_n7y",
        "outputId": "7983097f-9527-46a8-9885-81f9292ef7f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.8.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCv7JoPpclCA"
      },
      "outputs": [],
      "source": [
        "pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RY09Y37Ycp_4"
      },
      "outputs": [],
      "source": [
        "nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJFO7JlZdWpe"
      },
      "outputs": [],
      "source": [
        "pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI-qrWM8dmJu",
        "outputId": "ef817b44-3ec6-48e0-e33a-e30a0506170a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpSFAdnvYz1Q",
        "outputId": "00f3dd94-5e2b-4c25-b054-9345e8c7f870"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myqPXLMbdr7G"
      },
      "outputs": [],
      "source": [
        "torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Xo84n6ddysL"
      },
      "outputs": [],
      "source": [
        "torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXg66S_TAXIa"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Szt3x1IrAXfZ"
      },
      "outputs": [],
      "source": [
        "!pip install torch===1.6.0 torchvision===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCJNsbeDA8EM"
      },
      "outputs": [],
      "source": [
        "!apt-get install nvidia-384"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoFTOuu-yRUU",
        "outputId": "c2e81e15-a4fd-4a7f-92a0-920beb7d4ba0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SY7HI8gEyjSp"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhbscwAhyln6"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jrMIiMWGo-z"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eslOVWaAGozy"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJpq-MHRGog_"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJ_9wTX1OIvX",
        "outputId": "66b766c4-0138-4a77-aabc-3e13983eca9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/cloud-platform%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=IvzE9ODzDIqwPl-JOyVu18_Pmx_WfTky5tHkQtlcdNE&tc=fAw1vDpnYiRkXm5w63RXO5BM09VfWLDcWPZnZxHO4bk&cc=OddWaob_WEuv3DfWiJSD6YCA38zktlzp9guYm9EbYtU\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below.\n"
          ]
        }
      ],
      "source": [
        "import geemap\n",
        "Map = geemap.Map(center=[40,-100], zoom=4)\n",
        "Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pku1AG8TorOO"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "data = Map.user_roi\n",
        "# region = ee.FeatureCollection('users/ruanyongjian123/Yangtze_Plain_merge')\n",
        "# region_geo = region.geometry()\n",
        "region = ee.FeatureCollection('users/ruanyongjian123/Yangtze_Plain_merge')\n",
        "region_geo = region.geometry()\n",
        "span = 8.9831528*0.2\n",
        "fishnet = geemap.fishnet(region_geo, h_interval=span, v_interval=span, delta=1)\n",
        "Map.addLayer(fishnet, {}, 'ROI')\n",
        "Map.addLayer(region_geo, {}, 'ROI2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cadxrkZo6Um"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTn1e7iGbWnx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def get_img(asc_mosaic, aoi_arr, nums_aoi, time_sign):\n",
        "  task_arr = []\n",
        "  for i in range(nums_aoi):\n",
        "    tmp_name = str(i) + \"_fishnet\"\n",
        "    new_dir = \"/content/drive/MyDrive/\" + time_sign\n",
        "    if os.path.exists(new_dir)==False:\n",
        "      os.makedirs(new_dir)\n",
        "    feature = aoi_arr.get(i)\n",
        "    feature2 = ee.Feature(feature)\n",
        "    region_geo = feature2.geometry()\n",
        "    image_task = ee.batch.Export.image.toDrive(\n",
        "    image = asc_mosaic,\n",
        "    description=time_sign + \"_\" + tmp_name,\n",
        "    fileNamePrefix=time_sign + \"_\" + tmp_name,\n",
        "    folder = time_sign,\n",
        "    scale=10,\n",
        "    region=region_geo,\n",
        "    maxPixels = 1e13,\n",
        "    # fileDimensions=[25600, 25600]\n",
        "    )\n",
        "    task_arr.append(image_task)\n",
        "  return task_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8WNFC7tsDbv",
        "outputId": "8848bf30-10bf-48e8-e64f-e3ed52b2a329"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "41\n"
          ]
        }
      ],
      "source": [
        "nums_aoi = fishnet.size().getInfo()\n",
        "aoi_arr = fishnet.toList(nums_aoi)\n",
        "print(nums_aoi)\n",
        "sentinel_dataset = ee.ImageCollection(\"COPERNICUS/S1_GRD\").filter(ee.Filter.date('2022-09-11','2022-09-22')).filterBounds(region_geo).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH')).filter(ee.Filter.eq('instrumentMode', 'IW')).select(\"VV\").mosaic()\n",
        "sentinel_dataset = sentinel_dataset.toFloat()\n",
        "task_arr = get_img(sentinel_dataset, aoi_arr, nums_aoi, \"VV_0911-0922\")\n",
        "for task in task_arr:\n",
        "  task.start()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJKJtCoyKv9z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "region = ee.FeatureCollection('users/ruanyongjian123/Yangtze_Plain_merge')\n",
        "region_geo = region.geometry()\n",
        "# nums_aoi = region.size().getInfo()\n",
        "# aoi_arr = region.toList(nums_aoi)\n",
        "# aa = aoi_arr.get(0)\n",
        "# ff = aa.geometry()\n",
        "# print(ff)\n",
        "# sentinel_dataset = ee.ImageCollection('COPERNICUS/S1_GRD').filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).filter(ee.Filter.eq('instrumentMode', 'IW')).filter(ee.Filter.date('2022-08-22','2022-09-10')).filterBounds(region_geo)\n",
        "sentinel_dataset = ee.ImageCollection(\"COPERNICUS/S1_GRD\").filter(ee.Filter.date('2022-09-11','2022-09-22')).filterBounds(region_geo).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH')).filter(ee.Filter.eq('instrumentMode', 'IW')).select(\"VH\").mosaic()\n",
        "dirs = \"/content/drive/MyDrive/out\"\n",
        "out_dirs = \"/content/drive/MyDrive/poyang\"\n",
        "os.makedirs(\"/content/drive/MyDrive/VH_0911-0922\")\n",
        "image_task = ee.batch.Export.image.toDrive(\n",
        "    image = sentinel_dataset,\n",
        "    description='20220911-0922',\n",
        "    fileNamePrefix='VH_0911-0922',\n",
        "    folder = 'VH_0911-0922',\n",
        "    scale=10,\n",
        "    region=region_geo,\n",
        "    maxPixels = 1e13,\n",
        "    # fileDimensions=[25600, 25600]\n",
        "  )\n",
        "image_task.start()\n",
        "print('Running image export to Cloud Storage...')\n",
        "import time\n",
        "\n",
        "while image_task.active():\n",
        "  time.sleep(30)\n",
        "  if image_task.status()['state'] != 'COMPLETED':\n",
        "    print('Error with image export.')\n",
        "  else:\n",
        "    print('Image export completed.')\n",
        "    break\n",
        "\n",
        "# task_arr = get_img(asc_mosaic, aoi_arr, nums_aoi)\n",
        "\n",
        "# for task in task_arr:\n",
        "#   task.start()\n",
        "\n",
        "# while True:\n",
        "#   status_arr = []\n",
        "#   for task in task_arr:\n",
        "#     if task.active():\n",
        "\n",
        "#     if task.status()['state'] != 'COMPLETED':\n",
        "#       print('Error with image export.')\n",
        "#     else:\n",
        "#       print('Image export completed')\n",
        "#     status_arr.append(task.status()['state'])\n",
        "#     time.sleep(30)\n",
        "\n",
        "  # dirs = \"/content/drive/MyDrive/out\"\n",
        "  # out_dirs = \"/content/drive/MyDrive/poyang\"\n",
        "  # image_task = ee.batch.Export.image.toDrive(\n",
        "  #   image = asc_vh_mosaic,\n",
        "  #   description='poyang',\n",
        "  #   fileNamePrefix='poyang_data2',\n",
        "  #   folder = 'poyang',\n",
        "  #   scale=10,\n",
        "  #   region=region,\n",
        "  #   maxPixels = 1e12,\n",
        "  #   fileDimensions=[25600, 25600]\n",
        "  # )\n",
        "\n",
        "# image_task.start()\n",
        "# print('Running image export to Cloud Storage...')\n",
        "# import time\n",
        "\n",
        "# while image_task.active():\n",
        "#   L = len(os.listdir(out_dirs))\n",
        "#   if L % 5 == 0:\n",
        "#     print(L)\n",
        "#   time.sleep(30)\n",
        "\n",
        "# if image_task.status()['state'] != 'COMPLETED':\n",
        "#   print('Error with image export.')\n",
        "# else:\n",
        "#   print('Image export completed.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hdyGi5NyrJ3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "region = ee.FeatureCollection('users/ruanyongjian123/Yangtze_Plain_merge')\n",
        "region_geo = region.geometry()\n",
        "# nums_aoi = region.size().getInfo()\n",
        "# aoi_arr = region.toList(nums_aoi)\n",
        "# aa = aoi_arr.get(0)\n",
        "# ff = aa.geometry()\n",
        "# print(ff)\n",
        "# sentinel_dataset = ee.ImageCollection('COPERNICUS/S1_GRD').filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).filter(ee.Filter.eq('instrumentMode', 'IW')).filter(ee.Filter.date('2022-08-22','2022-09-10')).filterBounds(region_geo)\n",
        "sentinel_dataset = ee.ImageCollection(\"COPERNICUS/S1_GRD\").filter(ee.Filter.date('2022-09-11','2022-09-22')).filterBounds(region_geo).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH')).filter(ee.Filter.eq('instrumentMode', 'IW')).select(\"VV\").mosaic()\n",
        "dirs = \"/content/drive/MyDrive/out\"\n",
        "out_dirs = \"/content/drive/MyDrive/poyang\"\n",
        "os.makedirs(\"/content/drive/MyDrive/VV_0911-0922\")\n",
        "image_task = ee.batch.Export.image.toDrive(\n",
        "    image = sentinel_dataset,\n",
        "    description='20220911-0922',\n",
        "    fileNamePrefix='VV_0911-0922',\n",
        "    folder = 'VV_0911-0922',\n",
        "    scale=10,\n",
        "    region=region_geo,\n",
        "    maxPixels = 1e13,\n",
        "    # fileDimensions=[25600, 25600]\n",
        "  )\n",
        "image_task.start()\n",
        "print('Running image export to Cloud Storage...')\n",
        "import time\n",
        "\n",
        "while image_task.active():\n",
        "  time.sleep(30)\n",
        "  if image_task.status()['state'] != 'COMPLETED':\n",
        "    print('Error with image export.')\n",
        "  else:\n",
        "    print('Image export completed.')\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjC3nxLmywgG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "dirs = \"/content/drive/MyDrive/VH_0911-0922\"\n",
        "out_patch_dir = \"/content/drive/MyDrive/VH_0911-0922_patch\"\n",
        "os.makedirs(out_patch_dir)\n",
        "tif_files = glob.glob(dirs + \"/*.tif\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9my34Qmj3mK",
        "outputId": "4d7bada6-88b9-4d55-dd2e-facc47982529"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18081\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "dirs = \"/content/drive/MyDrive/VH_0911-0922_patch\"\n",
        "tif_files = glob.glob(dirs + \"/*.tif\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kw4e00CO1iFf"
      },
      "outputs": [],
      "source": [
        "from osgeo import ogr, osr, gdal\n",
        "import numpy as np\n",
        "def gen_data(filename, out_dir, size = 1000):\n",
        "  in_ds = gdal.Open(filename)\n",
        "  print(\"open tif file succeed\")\n",
        "  width = in_ds.RasterXSize\n",
        "  height = in_ds.RasterYSize\n",
        "  outbandsize = in_ds.RasterCount\n",
        "  im_geotrans = in_ds.GetGeoTransform()\n",
        "  im_proj = in_ds.GetProjection()\n",
        "  datatype = in_ds.GetRasterBand(1).DataType\n",
        "  in_band1 = in_ds.GetRasterBand(1)\n",
        "  offset_x = 0\n",
        "  offset_y = 0\n",
        "\n",
        "  col_num = int(width / size)\n",
        "  row_num = int(height / size)\n",
        "  if(width % size != 0):\n",
        "      col_num += 1\n",
        "  if(height % size != 0):\n",
        "      row_num += 1\n",
        "\n",
        "  num = 1\n",
        "  tmp = filename.split(\"/\")[-1]\n",
        "  tmp_name = tmp.split(\".\")[0]\n",
        "  print(filename, \"row_num:%d   col_num:%d\" %(row_num,col_num))\n",
        "  for i in range(row_num):\n",
        "      for j in range(col_num):\n",
        "          offset_x = i * size\n",
        "          offset_y = j * size\n",
        "          b_ysize = min(width - offset_y, size)\n",
        "          b_xsize = min(height - offset_x, size)\n",
        "          files = out_dir + \"/\" + tmp_name + \"_\" + str(i) + \"_\" + str(j) +\"_.tif\"\n",
        "          if os.path.exists(files):\n",
        "            continue\n",
        "          out_band1 = in_band1.ReadAsArray(offset_y, offset_x, b_ysize, b_xsize)\n",
        "          gtif_driver = gdal.GetDriverByName(\"GTiff\")\n",
        "\n",
        "          if num % 10 == 0:\n",
        "            print('total nums:', row_num * col_num, \"remain:\", row_num * col_num - num)\n",
        "          out_ds = gtif_driver.Create(files, b_ysize, b_xsize, outbandsize, datatype)\n",
        "\n",
        "          ori_transform = in_ds.GetGeoTransform()\n",
        "\n",
        "          top_left_x = ori_transform[0]\n",
        "          w_e_pixel_resolution = ori_transform[1]\n",
        "          top_left_y = ori_transform[3]\n",
        "          n_s_pixel_resolution = ori_transform[5]\n",
        "\n",
        "          top_left_x = top_left_x + offset_x * w_e_pixel_resolution\n",
        "          top_left_y = top_left_y + offset_y * n_s_pixel_resolution\n",
        "          dst_transform = (top_left_x, ori_transform[1], ori_transform[2], top_left_y, ori_transform[4], ori_transform[5])\n",
        "          out_ds.SetGeoTransform(dst_transform)\n",
        "          out_ds.SetProjection(in_ds.GetProjection())\n",
        "          out_ds.GetRasterBand(1).WriteArray(out_band1)\n",
        "          out_ds.FlushCache()\n",
        "          num+=1\n",
        "          del out_ds,out_band1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUg9Eky40QuA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "dirs = \"/content/drive/MyDrive/VH_0911-0922\"\n",
        "out_patch_dir = \"/content/drive/MyDrive/VH_0911-0922_patch\"\n",
        "tif_files = glob.glob(dirs + \"/*.tif\")\n",
        "for files in tif_files:\n",
        "  gen_data(files, out_patch_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqgNhxAfy0yy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import argparse\n",
        "import numpy as np\n",
        "import os,time,cv2\n",
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "import tifffile as tiff\n",
        "import gdal\n",
        "from osgeo import gdal_array\n",
        "import gdalnumeric\n",
        "from osgeo import ogr, osr, gdal\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "\n",
        "def get_data(filename):\n",
        "    in_ds = gdal.Open(filename)\n",
        "    print(\"open tif file succeed\")\n",
        "    width = in_ds.RasterXSize\n",
        "    height = in_ds.RasterYSize\n",
        "    outbandsize = in_ds.RasterCount\n",
        "    im_geotrans = in_ds.GetGeoTransform()\n",
        "    im_proj = in_ds.GetProjection()\n",
        "    datatype = in_ds.GetRasterBand(1).DataType\n",
        "    return in_ds, width, height, outbandsize, datatype, im_geotrans, im_proj\n",
        "\n",
        "def clip_data_sar(im_data, width, height, outbandsize, datatype, out_dir, size):\n",
        "    count = 0\n",
        "    in_band1 = im_data.GetRasterBand(1)\n",
        "\n",
        "    col_num = int(width / size)\n",
        "    row_num = int(height / size)\n",
        "\n",
        "    num = 0\n",
        "\n",
        "    print(\"row_num:%d   col_num:%d\" %(row_num,col_num))\n",
        "    for i in range(row_num):\n",
        "        for j in range(col_num):\n",
        "            offset_x = j * size\n",
        "            offset_y = i * size\n",
        "\n",
        "            b_ysize = size #min(width - offset_y, size)\n",
        "            b_xsize = size #min(height - offset_x, size)\n",
        "\n",
        "            out_band1 = in_band1.ReadAsArray(offset_x, offset_y, b_ysize, b_xsize)\n",
        "\n",
        "\n",
        "            gtif_driver = gdal.GetDriverByName(\"GTiff\")\n",
        "            file = out_dir + \"/\" + str(i) + \"_\" + str(j) +\"_.tiff\"\n",
        "            num += 1\n",
        "            out_ds = gtif_driver.Create(file, b_ysize, b_xsize, outbandsize, datatype)\n",
        "            ori_transform = im_data.GetGeoTransform()\n",
        "\n",
        "            top_left_x = ori_transform[0]\n",
        "            w_e_pixel_resolution = ori_transform[1]\n",
        "            top_left_y = ori_transform[3]\n",
        "            n_s_pixel_resolution = ori_transform[5]\n",
        "\n",
        "            top_left_x = top_left_x + offset_x * w_e_pixel_resolution\n",
        "            top_left_y = top_left_y + offset_y * n_s_pixel_resolution\n",
        "\n",
        "            dst_transform = (top_left_x, ori_transform[1], ori_transform[2], top_left_y, ori_transform[4], ori_transform[5])\n",
        "            out_ds.SetGeoTransform(dst_transform)\n",
        "\n",
        "            out_ds.GetRasterBand(1).WriteArray(out_band1)\n",
        "\n",
        "            out_ds.FlushCache()\n",
        "            del out_ds, out_band1\n",
        "\n",
        "    print(count)\n",
        "\n",
        "sar_data, width, height, outbandsize, datatype, im_geotrans, im_proj  = get_data(r\"/content/drive/MyDrive/poyang/poyang_data2.tif\")\n",
        "clip_data_sar(sar_data, width, height, outbandsize, datatype, \"/content/drive/MyDrive/out\", size = 1000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LylMqfYskod",
        "outputId": "c21b8283-e88d-48d2-ba74-39bcf8e3087f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/VH_0911-0922_patch/VH_0911-0922_38_fishnet_15_8_.tif\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:142: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:85: RuntimeWarning: invalid value encountered in true_divide\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import segmentation\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import tifffile as tiff\n",
        "from skimage.util import img_as_float\n",
        "\n",
        "import gdal\n",
        "\n",
        "def get_data(filename):\n",
        "  in_ds = gdal.Open(filename)\n",
        "  width = in_ds.RasterXSize  #\n",
        "  height = in_ds.RasterYSize  #\n",
        "  outbandsize = in_ds.RasterCount  #\n",
        "  im_geotrans = in_ds.GetGeoTransform()  #\n",
        "  im_proj = in_ds.GetProjection()  #\n",
        "  datatype = in_ds.GetRasterBand(1).DataType\n",
        "  return in_ds, width, height, outbandsize, datatype, im_geotrans, im_proj\n",
        "\n",
        "def sample_wise_standardization(data):\n",
        "  import math\n",
        "  _mean = np.mean(data)\n",
        "  _std = np.std(data)\n",
        "  npixel = np.size(data) * 1.0\n",
        "  min_stddev = 1.0 / math.sqrt(npixel)\n",
        "  return (data - _mean) / max(_std, min_stddev)\n",
        "\n",
        "\n",
        "class Args(object):\n",
        "  input_image_path = 'image/aerial.jpg'  # image/coral.jpg image/tiger.jpg\n",
        "  train_epoch = 2 ** 7\n",
        "  mod_dim1 = 16  #\n",
        "  mod_dim2 = 16\n",
        "  gpu_id = 0\n",
        "\n",
        "  min_label_num = 5  # if the label number small than it, break loop\n",
        "  max_label_num = 256  # if the label number small than it, start to show result image.\n",
        "\n",
        "\n",
        "class MyNet(nn.Module):\n",
        "  def __init__(self, inp_dim, mod_dim1, mod_dim2):\n",
        "    super(MyNet, self).__init__()\n",
        "\n",
        "    self.seq = nn.Sequential(\n",
        "        nn.Conv2d(inp_dim, mod_dim1, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(mod_dim1),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.Conv2d(mod_dim1, mod_dim2, kernel_size=1, stride=1, padding=0),\n",
        "        nn.BatchNorm2d(mod_dim2),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.Conv2d(mod_dim2, mod_dim1, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(mod_dim1),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.Conv2d(mod_dim1, mod_dim2, kernel_size=1, stride=1, padding=0),\n",
        "        nn.BatchNorm2d(mod_dim2),\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.seq(x)\n",
        "\n",
        "\n",
        "def run(filename, dirs):\n",
        "  args = Args()\n",
        "  torch.cuda.manual_seed_all(1943)\n",
        "  np.random.seed(1943)\n",
        "  os.environ['CUDA_VISIBLE_DEVICES'] = str(args.gpu_id)  # choose GPU:0\n",
        "  tmp_ = filename.split(\"/\")\n",
        "  fff = dirs + \"/\" + tmp_[-1]\n",
        "  if os.path.exists(fff):\n",
        "    return\n",
        "  image = tiff.imread(filename)\n",
        "  h, w = image.shape\n",
        "  if h!= 1000 or w!=1000:\n",
        "    return\n",
        "  image[image != image] = -15\n",
        "\n",
        "  image = img_as_float(image[:, :])\n",
        "  image = (image - np.min(image)) / (np.max(image) - np.min(image)) * 255\n",
        "  image = image[:, :]\n",
        "  image = image.astype(np.uint8)\n",
        "\n",
        "  '''segmentation ML'''\n",
        "  # seg_map = segmentation.felzenszwalb(image, scale=32, sigma=0.5, min_size=64)\n",
        "  #seg_map = segmentation.felzenszwalb(image, scale=100, sigma=0.5, min_size=32)\n",
        "  seg_map = segmentation.felzenszwalb(image, scale=100, sigma=0.5, min_size=16)\n",
        "  #seg_map = segmentation.felzenszwalb(image)\n",
        "  # seg_map = segmentation.slic(image, n_segments=10000, compactness=100)\n",
        "  seg_map = seg_map.flatten()\n",
        "  seg_lab = [np.where(seg_map == u_label)[0]\n",
        "              for u_label in np.unique(seg_map)]\n",
        "\n",
        "  '''train init'''\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "  tensor = sample_wise_standardization(image)\n",
        "  tensor = np.expand_dims(tensor, axis = 2)\n",
        "\n",
        "  tensor = tensor.transpose((2, 0, 1))\n",
        "  tensor = tensor.astype(np.float32) / 255.0\n",
        "  tensor = tensor[np.newaxis, :, :, :]\n",
        "  tensor = torch.from_numpy(tensor).to(device)\n",
        "\n",
        "  model = MyNet(inp_dim=1, mod_dim1=args.mod_dim1, mod_dim2=args.mod_dim2).to(device)\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=1e-1, momentum=0.9)\n",
        "    # optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-1, momentum=0.0)\n",
        "\n",
        "  image_flatten = image.reshape((-1, 1))\n",
        "  color_avg = np.random.randint(255, size=(args.max_label_num, 1))\n",
        "  show = image\n",
        "  model.train()\n",
        "  for batch_idx in range(args.train_epoch):\n",
        "    '''forward'''\n",
        "    optimizer.zero_grad()\n",
        "    output = model(tensor)[0]\n",
        "    output = output.permute(1, 2, 0).view(-1, args.mod_dim2)\n",
        "    target = torch.argmax(output, 1)\n",
        "    im_target = target.data.cpu().numpy()\n",
        "\n",
        "    '''refine'''\n",
        "    for inds in seg_lab:\n",
        "      u_labels, hist = np.unique(im_target[inds], return_counts=True)\n",
        "      im_target[inds] = u_labels[np.argmax(hist)]\n",
        "\n",
        "    target = torch.from_numpy(im_target)\n",
        "    target = target.to(device)\n",
        "    loss = criterion(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    un_label, lab_inverse = np.unique(im_target, return_inverse=True, )\n",
        "    if un_label.shape[0] < args.max_label_num:  # update show\n",
        "      img_flatten = image_flatten.copy()\n",
        "      if len(color_avg) != un_label.shape[0]:\n",
        "        color_avg = [np.mean(img_flatten[im_target == label], axis=0, dtype=np.int) for label in un_label]\n",
        "      for lab_id, color in enumerate(color_avg):\n",
        "        img_flatten[lab_inverse == lab_id] = color\n",
        "      show = img_flatten.reshape(image.shape)\n",
        "    tmp2 = filename.split(\"/\")\n",
        "    if len(un_label) < args.min_label_num:\n",
        "      break\n",
        "  tmp22 = filename.split(\"/\")\n",
        "  tiff.imwrite(dirs + \"/\" + tmp22[-1], show)\n",
        "\n",
        "dirs = \"/content/drive/MyDrive/VH_0911-0922_patch\"\n",
        "tif_files = glob.glob(dirs + \"/*.tif\")\n",
        "new_dirs = \"/content/drive/MyDrive/VH_0911-0922_patch_seg\"\n",
        "num = 0\n",
        "for filename in tif_files:\n",
        "  run(filename, new_dirs)\n",
        "  if num % 100 ==0:\n",
        "    print(filename)\n",
        "    num += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5qyyg1TbIo5"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGpp-O5LSDg6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import segmentation\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import tifffile as tiff\n",
        "from skimage.util import img_as_float\n",
        "\n",
        "import gdal\n",
        "\n",
        "def get_data(filename):\n",
        "    in_ds = gdal.Open(filename)\n",
        "    # print(\"open tif file succeed\")\n",
        "    width = in_ds.RasterXSize  #\n",
        "    height = in_ds.RasterYSize  #\n",
        "    outbandsize = in_ds.RasterCount  #\n",
        "    im_geotrans = in_ds.GetGeoTransform()  #\n",
        "    im_proj = in_ds.GetProjection()  #\n",
        "    datatype = in_ds.GetRasterBand(1).DataType\n",
        "    return in_ds, width, height, outbandsize, datatype, im_geotrans, im_proj\n",
        "\n",
        "\n",
        "def sample_wise_standardization(data):\n",
        "\n",
        "\n",
        "    import math\n",
        "    _mean = np.mean(data)\n",
        "    _std = np.std(data)\n",
        "    npixel = np.size(data) * 1.0\n",
        "    min_stddev = 1.0 / math.sqrt(npixel)\n",
        "    return (data - _mean) / max(_std, min_stddev)\n",
        "\n",
        "\n",
        "class Args(object):\n",
        "    input_image_path = 'image/aerial.jpg'  # image/coral.jpg image/tiger.jpg\n",
        "    train_epoch = 2 ** 7\n",
        "    mod_dim1 = 16  #\n",
        "    mod_dim2 = 16\n",
        "    gpu_id = 0\n",
        "\n",
        "    min_label_num = 5  # if the label number small than it, break loop\n",
        "    max_label_num = 256  # if the label number small than it, start to show result image.\n",
        "\n",
        "\n",
        "class MyNet(nn.Module):\n",
        "    def __init__(self, inp_dim, mod_dim1, mod_dim2):\n",
        "        super(MyNet, self).__init__()\n",
        "\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv2d(inp_dim, mod_dim1, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(mod_dim1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(mod_dim1, mod_dim2, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(mod_dim2),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(mod_dim2, mod_dim1, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(mod_dim1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(mod_dim1, mod_dim2, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(mod_dim2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.seq(x)\n",
        "\n",
        "\n",
        "def run(filename, dirs):\n",
        "    # world, width, height, outbandsize, datatype, im_geotrans, im_proj = get_data(filename)\n",
        "\n",
        "   # start_time0 = time.time()\n",
        "\n",
        "    args = Args()\n",
        "    torch.cuda.manual_seed_all(1943)\n",
        "    np.random.seed(1943)\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = str(args.gpu_id)  # choose GPU:0\n",
        "\n",
        "    image = tiff.imread(filename)\n",
        "    image[image != image] = -15\n",
        "\n",
        "    image = img_as_float(image[:, :])\n",
        "    image = (image - np.min(image)) / (np.max(image) - np.min(image)) * 255\n",
        "    image = image[:, :]\n",
        "    image = image.astype(np.uint8)\n",
        "\n",
        "    '''segmentation ML'''\n",
        "    # seg_map = segmentation.felzenszwalb(image, scale=32, sigma=0.5, min_size=64)\n",
        "    #seg_map = segmentation.felzenszwalb(image, scale=100, sigma=0.5, min_size=32)\n",
        "    seg_map = segmentation.felzenszwalb(image, scale=100, sigma=0.5, min_size=16)\n",
        "    #seg_map = segmentation.felzenszwalb(image)\n",
        "    # seg_map = segmentation.slic(image, n_segments=10000, compactness=100)\n",
        "    seg_map = seg_map.flatten()\n",
        "    seg_lab = [np.where(seg_map == u_label)[0]\n",
        "               for u_label in np.unique(seg_map)]\n",
        "\n",
        "    '''train init'''\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    tensor = sample_wise_standardization(image)\n",
        "    tensor = np.expand_dims(tensor, axis = 2)\n",
        "\n",
        "    tensor = tensor.transpose((2, 0, 1))\n",
        "    tensor = tensor.astype(np.float32) / 255.0\n",
        "    tensor = tensor[np.newaxis, :, :, :]\n",
        "    tensor = torch.from_numpy(tensor).to(device)\n",
        "\n",
        "    model = MyNet(inp_dim=1, mod_dim1=args.mod_dim1, mod_dim2=args.mod_dim2).to(device)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-1, momentum=0.9)\n",
        "    # optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-1, momentum=0.0)\n",
        "\n",
        "    image_flatten = image.reshape((-1, 1))\n",
        "    color_avg = np.random.randint(255, size=(args.max_label_num, 1))\n",
        "    show = image\n",
        "\n",
        "    '''train loop'''\n",
        "    #start_time1 = time.time()\n",
        "    model.train()\n",
        "    for batch_idx in range(args.train_epoch):\n",
        "        '''forward'''\n",
        "        optimizer.zero_grad()\n",
        "        output = model(tensor)[0]\n",
        "        output = output.permute(1, 2, 0).view(-1, args.mod_dim2)\n",
        "        target = torch.argmax(output, 1)\n",
        "        im_target = target.data.cpu().numpy()\n",
        "\n",
        "        '''refine'''\n",
        "        for inds in seg_lab:\n",
        "            u_labels, hist = np.unique(im_target[inds], return_counts=True)\n",
        "            im_target[inds] = u_labels[np.argmax(hist)]\n",
        "\n",
        "        '''backward'''\n",
        "        target = torch.from_numpy(im_target)\n",
        "        target = target.to(device)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        '''show image'''\n",
        "        un_label, lab_inverse = np.unique(im_target, return_inverse=True, )\n",
        "        if un_label.shape[0] < args.max_label_num:  # update show\n",
        "            img_flatten = image_flatten.copy()\n",
        "            if len(color_avg) != un_label.shape[0]:\n",
        "                color_avg = [np.mean(img_flatten[im_target == label], axis=0, dtype=np.int) for label in un_label]\n",
        "            for lab_id, color in enumerate(color_avg):\n",
        "                img_flatten[lab_inverse == lab_id] = color\n",
        "            show = img_flatten.reshape(image.shape)\n",
        "        # cv2.imshow(\"seg_pt\", show)\n",
        "        tmp2 = filename.split(\"/\")\n",
        "        # ttt = show.astype(np.uint8)\n",
        "        # if batch_idx % 15 == 0:\n",
        "        #     cv2.imwrite(dirs + \"/\" + str(batch_idx) + \"_\" + tmp2[-1], ttt)\n",
        "        #cv2.waitKey(1)\n",
        "\n",
        "       # print('Loss:', batch_idx, loss.item())\n",
        "        if len(un_label) < args.min_label_num:\n",
        "            break\n",
        "    tmp22 = filename.split(\"/\")\n",
        "    tiff.imwrite(dirs + \"/\" + tmp22[-1], show)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    dirs = \"/content/drive/MyDrive/VH_0911-0922_patch\"\n",
        "    tif_files = glob.glob(dirs + \"/*.tif\")\n",
        "    new_dirs = \"/content/drive/MyDrive/VH_0911-0922_patch_seg\"\n",
        "    # os.makedirs(new_dirs)\n",
        "    num = 0\n",
        "    for filename in tif_files:\n",
        "        run(filename, new_dirs)\n",
        "        num += 1\n",
        "        if num % 100 ==0:\n",
        "            print(num)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}